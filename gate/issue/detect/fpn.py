
# -*- coding: utf-8 -*-
"""
DECTRION FRAMEWORK

Copyright (c) 2017 Kai JIN.
Licensed under the MIT License (see LICENSE for details)
Written by Kai JIN
Updated on 2018/4/19

--------------------------------------------------------

Feature Pyramid Network:
[1] Lin, T.-Y., DollÃ¡r, P., Girshick, R., He, K., Hariharan, B., & Belongie,
    S. (2016). Feature Pyramid Networks for Object Detection.
    https://doi.org/10.1109/CVPR.2017.106

A Standard inputs include {C2, C3, C4, C5} in respect to the original image
with ratio {4, 8, 16, 32}

"""

import tensorflow as tf
import keras.backend as K
from gate.layer.ops import *
from gate.issue.detect import roi


def fpn_resnet_graph(feature_maps, scope='fpn'):
  """ FPN graph: we assume input 4-level feature maps.
  Inputs:
    feature_maps: [n, N, H, W, C] a list including feature maps from
                  diff layers.
  """
  with tf.variable_scope(scope):
    assert len(feature_maps) == 4
    C2, C3, C4, C5 = feature_maps
    # fpn
    P5 = conv2d(C5, 256, 1, 1, 'c5p5')
    P4 = deconv2d(P5, 256, 2, 2, 'p5up') + conv2d(C4, 256, 1, 1, 'c4p4')
    P3 = deconv2d(P4, 256, 2, 2, 'p4up') + conv2d(C3, 256, 1, 1, 'c3p3')
    P2 = deconv2d(P3, 256, 2, 2, 'p3up') + conv2d(C2, 256, 1, 1, 'c2p2')
    # Attach 3x3 conv to all P layers to get the final feature maps.
    P2 = conv2d(P2, 256, 3, 1, 'p2')
    P3 = conv2d(P3, 256, 3, 1, 'p3')
    P4 = conv2d(P4, 256, 3, 1, 'p4')
    P5 = conv2d(P5, 256, 3, 1, 'p5')
    # P6 is used for the 5th anchor scale in RPN. Generated by
    # subsampling from P5 with stride of 2.
    P6 = max_pool2d(P5, 2, 2, padding='SAME', name='p6')
    return [P2, P3, P4, P5, P6]


def fpn_classifier_graph(rois, feature_maps, image_meta,
                         pool_size, num_classes, is_training):
  """ Builds the computation graph of the feature pyramid network classifier
    and regressor heads.

    rois: [batch, num_rois, (y1, x1, y2, x2)] Proposal boxes in normalized
          coordinates.
    feature_maps: List of feature maps from diffent layers of the pyramid,
                  [P2, P3, P4, P5]. Each has a different resolution.
    - image_meta: [batch, (meta data)] Image details. See compose_image_meta()
    pool_size: The width of the square feature map generated from ROI Pooling.
    num_classes: number of classes, which determines the depth of the results
    is_training: Boolean. Train or freeze Batch Norm layres

    Returns:
        logits: [N, NUM_CLASSES] classifier logits (before softmax)
        probs: [N, NUM_CLASSES] classifier probabilities
        bbox_deltas: [N, (dy, dx, log(dh), log(dw))] Deltas to apply to
                    proposal boxes
  """
  # ROI Pooling
  # Shape: [batch, num_boxes, pool_height, pool_width, channels]
  x = roi.PyramidROIAlign(rois, image_meta, feature_maps,
                          [pool_size, pool_size])
  R, H, W, C = x.get_shape().as_list()[1:]
  # to construct 4-D for conv operation
  x = tf.reshape(x, [-1, H, W, C])
  x = conv2d(x, 1024, 7, 1, padding='VALID', name='mrcnn_class_conv1')
  x = relu(bn(x, is_training=is_training, scope='mrcnn_class_bn1'))
  x = conv2d(x, 1024, 1, 1, name='mrcnn_class_conv2')
  x = relu(bn(x, is_training=is_training, scope='mrcnn_class_bn2'))
  x = tf.squeeze(x, axis=[1, 2], name='pool_squeeze')

  # classifier head
  mrcnn_class_logits = linear(x, num_classes, scope='mrcnn_class_linear')
  mrcnn_probs = tf.nn.softmax(mrcnn_class_logits)
  mrcnn_class_logits = tf.reshape(
      mrcnn_class_logits, [-1, R, num_classes], 'mrcnn_class_logits')
  mrcnn_probs = tf.reshape(
      mrcnn_probs, [-1, R, num_classes], 'mrcnn_class')

  # bbox head
  # [batch, boxes, num_classes * (dy, dx, log(dh), log(dw))]
  x = linear(x, num_classes*4, 'mrcnn_bbox_fc')
  # Reshape to [batch, boxes, num_classes, (dy, dx, log(dh), log(dw))]
  mrcnn_bbox = tf.reshape(x, [-1, R, num_classes, 4], 'mrcnn_bbox')

  return mrcnn_class_logits, mrcnn_probs, mrcnn_bbox


def fpn_mask_graph(rois, feature_maps, image_meta,
                   pool_size, num_classes, is_training):
  """ Builds the computation graph of the mask head of Feature Pyramid Network.

    rois: [batch, num_rois, (y1, x1, y2, x2)] Proposal boxes in normalized
          coordinates.
    feature_maps: List of feature maps from diffent layers of the pyramid,
                  [P2, P3, P4, P5]. Each has a different resolution.
    image_meta: [batch, (meta data)] Image details. See compose_image_meta()
    pool_size: The width of the square feature map generated from ROI Pooling.
    num_classes: number of classes, which determines the depth of the results
    is_training: Boolean. Train or freeze Batch Norm layres

    Returns: Masks [batch, roi_count, height, width, num_classes]
  """
  # ROI Pooling
  # Shape: [batch, num_boxes, pool_height, pool_width, channels]
  x = roi.PyramidROIAlign(rois, image_meta, feature_maps,
                          [pool_size, pool_size])
  R, H, W, C = x.get_shape().as_list()[1:]
  x = tf.reshape(x, [-1, H, W, C])
  x = conv2d(x, 256, 3, 1, name='mrcnn_mask_conv1')
  x = relu(bn(x, is_training=is_training, scope='mrcnn_mask_bn1'))
  x = conv2d(x, 256, 3, 1, name='mrcnn_mask_conv2')
  x = relu(bn(x, is_training=is_training, scope='mrcnn_mask_bn2'))
  x = conv2d(x, 256, 3, 1, name='mrcnn_mask_conv3')
  x = relu(bn(x, is_training=is_training, scope='mrcnn_mask_bn3'))
  x = conv2d(x, 256, 3, 1, name='mrcnn_mask_conv4')
  x = relu(bn(x, is_training=is_training, scope='mrcnn_mask_bn4'))
  x = relu(deconv2d(x, 256, 2, 2, name='mrcnn_mask_deconv'))
  x = conv2d(x, num_classes, 1, 1, name='mrcnn_mask_conv5')
  x = tf.reshape(tf.sigmoid(x), [-1, R, H*2, W*2, num_classes], 'mrcnn_mask')
  return x


def mrcnn_class_loss_graph(target_class_ids, pred_class_logits,
                           active_class_ids):
  """Loss for the classifier head of Mask RCNN.

  target_class_ids: [batch, num_rois]. Integer class IDs. Uses zero
      padding to fill in the array.
  pred_class_logits: [batch, num_rois, num_classes]
  active_class_ids: [batch, num_classes]. Has a value of 1 for
      classes that are in the dataset of the image, and 0
      for classes that are not in the dataset.
  """
  target_class_ids = tf.cast(target_class_ids, 'int64')

  # Find predictions of classes that are not in the dataset.
  pred_class_ids = tf.argmax(pred_class_logits, axis=2)
  # TODO: Update this line to work with batch > 1. Right now it assumes all
  #       images in a batch have the same active_class_ids
  pred_active = tf.gather(active_class_ids[0], pred_class_ids)

  # Loss
  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(
      labels=target_class_ids, logits=pred_class_logits)

  # Erase losses of predictions of classes that are not in the active
  # classes of the image.
  loss = loss * pred_active

  # Computer loss mean. Use only predictions that contribute
  # to the loss to get a correct mean.
  loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)
  return loss


def mrcnn_bbox_loss_graph(target_bbox, target_class_ids, pred_bbox):
  """Loss for Mask R-CNN bounding box refinement.

  target_bbox: [batch, num_rois, (dy, dx, log(dh), log(dw))]
  target_class_ids: [batch, num_rois]. Integer class IDs.
  pred_bbox: [batch, num_rois, num_classes, (dy, dx, log(dh), log(dw))]
  """
  # Reshape to merge batch and roi dimensions for simplicity.
  target_class_ids = K.reshape(target_class_ids, (-1,))
  target_bbox = K.reshape(target_bbox, (-1, 4))
  pred_bbox = K.reshape(pred_bbox, (-1, K.int_shape(pred_bbox)[2], 4))

  # Only positive ROIs contribute to the loss. And only
  # the right class_id of each ROI. Get their indicies.
  positive_roi_ix = tf.where(target_class_ids > 0)[:, 0]
  positive_roi_class_ids = tf.cast(
      tf.gather(target_class_ids, positive_roi_ix), tf.int64)
  indices = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)

  # Gather the deltas (predicted and true) that contribute to loss
  target_bbox = tf.gather(target_bbox, positive_roi_ix)
  pred_bbox = tf.gather_nd(pred_bbox, indices)

  # Smooth-L1 Loss
  loss = K.switch(tf.size(target_bbox) > 0,
                  smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),
                  tf.constant(0.0))
  loss = K.mean(loss)
  return loss


def mrcnn_mask_loss_graph(target_masks, target_class_ids, pred_masks):
  """Mask binary cross-entropy loss for the masks head.

  target_masks: [batch, num_rois, height, width].
      A float32 tensor of values 0 or 1. Uses zero padding to fill array.
  target_class_ids: [batch, num_rois]. Integer class IDs. Zero padded.
  pred_masks: [batch, proposals, height, width, num_classes] float32 tensor
              with values from 0 to 1.
  """
  # Reshape for simplicity. Merge first two dimensions into one.
  target_class_ids = K.reshape(target_class_ids, (-1,))
  mask_shape = tf.shape(target_masks)
  target_masks = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))
  pred_shape = tf.shape(pred_masks)
  pred_masks = K.reshape(pred_masks,
                         (-1, pred_shape[2], pred_shape[3], pred_shape[4]))
  # Permute predicted masks to [N, num_classes, height, width]
  pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])

  # Only positive ROIs contribute to the loss. And only
  # the class specific mask of each ROI.
  positive_ix = tf.where(target_class_ids > 0)[:, 0]
  positive_class_ids = tf.cast(
      tf.gather(target_class_ids, positive_ix), tf.int64)
  indices = tf.stack([positive_ix, positive_class_ids], axis=1)

  # Gather the masks (predicted and true) that contribute to loss
  y_true = tf.gather(target_masks, positive_ix)
  y_pred = tf.gather_nd(pred_masks, indices)

  # Compute binary cross entropy. If no positive ROIs, then return 0.
  # shape: [batch, roi, num_classes]
  loss = K.switch(tf.size(y_true) > 0,
                  K.binary_crossentropy(target=y_true, output=y_pred),
                  tf.constant(0.0))
  loss = K.mean(loss)
  return loss


def smooth_l1_loss(y_true, y_pred):
  """Implements Smooth-L1 loss.
  y_true and y_pred are typicallly: [N, 4], but could be any shape.
  """
  diff = K.abs(y_true - y_pred)
  less_than_one = K.cast(K.less(diff, 1.0), "float32")
  loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)
  return loss
